{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sys.path.append(\"/home/mschlupp/pythonTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check what we have to do first\n",
    "evts = pd.read_csv(\"files/finalSets/evts_noApp_phone.csv\", nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>usageDay</th>\n",
       "      <th>isTrain</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>nEvts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>121.38</td>\n",
       "      <td>31.24</td>\n",
       "      <td>Sun</td>\n",
       "      <td>00:55:25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M39+</td>\n",
       "      <td>小米</td>\n",
       "      <td>红米note</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>106.60</td>\n",
       "      <td>29.70</td>\n",
       "      <td>Sun</td>\n",
       "      <td>00:08:05</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>M39+</td>\n",
       "      <td>魅族</td>\n",
       "      <td>MX4 Pro</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            device_id  longitude  latitude  day      time  hour  \\\n",
       "0         1    29182687948017175     121.38     31.24  Sun  00:55:25     0   \n",
       "1         3 -4833982096941402721     106.60     29.70  Sun  00:08:05     0   \n",
       "\n",
       "   usageDay  isTrain group phone_brand device_model  nEvts  \n",
       "0         3        1  M39+          小米       红米note    256  \n",
       "1         3        1  M39+          魅族      MX4 Pro    248  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model variables\n",
    "We'll build our model based on:\n",
    "* `device_model`\n",
    "* `phone_brand`\n",
    "* `usageDay`\n",
    "* `hour`\n",
    "* `nEvts`\n",
    "* `longitude` and `latitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"files/finalSets/evts_noApp_phone.csv\")\n",
    "data = data.drop([\"event_id\",\"day\",\"time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=[0, 1, 2, 3, 4], dtype=<class 'float'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_brand = LabelEncoder()\n",
    "enc_device = LabelEncoder()\n",
    "enc_group = LabelEncoder()\n",
    "data[\"phone_brand\"] = enc_brand.fit_transform(data.phone_brand)\n",
    "data[\"device_model\"] = enc_device.fit_transform(data.device_model)\n",
    "data[\"group\"] = enc_group.fit_transform(data.group)\n",
    "\n",
    "scaler_long = RobustScaler()\n",
    "scaler_lat = RobustScaler()\n",
    "scaler_nevts = RobustScaler()\n",
    "data[\"latitude\"] = scaler_lat.fit_transform(data.latitude.reshape(-1,1))\n",
    "data[\"longitude\"] = scaler_long.fit_transform(data.longitude.reshape(-1,1))\n",
    "#data[\"nEvts\"] = scaler_nevts.fit_transform(data.nEvts.reshape(-1,1))\n",
    "\n",
    "lr_enc = OneHotEncoder(categorical_features=[0,1,2,3,4])\n",
    "lr_enc.fit(data.drop([\"isTrain\",\"device_id\",\"group\",\"longitude\",\"latitude\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>hour</th>\n",
       "      <th>usageDay</th>\n",
       "      <th>isTrain</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>nEvts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>710</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>-1.273529</td>\n",
       "      <td>-0.151606</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>340</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  longitude  latitude  hour  usageDay  isTrain  group  \\\n",
       "0    29182687948017175   0.900000  0.003012     0         3        1     11   \n",
       "1 -4833982096941402721  -1.273529 -0.151606     0         3        1     11   \n",
       "\n",
       "   phone_brand  device_model  nEvts  \n",
       "0           24           710    256  \n",
       "1           64           340    248  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_list = [\"isTrain\"]\n",
    "train = data[data.isTrain==1].drop( drop_list, axis=1)\n",
    "true_classes = train.group\n",
    "test = data[data.isTrain==0].drop( drop_list+[\"group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train\n",
    "                                                  , true_classes, test_size=0.3\n",
    "                                                  ,random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_drop = [\"group\",\"device_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device_id', 'longitude', 'latitude', 'hour', 'usageDay', 'group',\n",
       "       'phone_brand', 'device_model', 'nEvts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: linear logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2'\n",
    "                        , C=0.1 # was 0.05\n",
    "                        , tol=0.00001 # was 0.0001\n",
    "                        , solver='lbfgs'\n",
    "                        , max_iter=600\n",
    "                        , multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=600, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=1e-05, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(lr_enc.transform(x_train.drop(train_drop+[\"latitude\",\"longitude\"],axis=1)),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss):\n",
    "    print(\"Test MVA predictions on test and training set:\\n\")\n",
    "    print(\"Log loss on training set: \", loss(y_tr,p_tr))\n",
    "    print(\"Log loss on test set: \", loss(y_te,p_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_lr_train = lr.predict_proba(lr_enc.transform(x_train.drop(train_drop+[\"latitude\",\"longitude\"],axis=1)))\n",
    "probs_lr_val = lr.predict_proba(lr_enc.transform(x_val.drop(train_drop+[\"latitude\",\"longitude\"],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  1.04151752526\n",
      "Log loss on test set:  1.05119874793\n"
     ]
    }
   ],
   "source": [
    "printLoss(y_train, probs_lr_train, y_val, probs_lr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average the predictions in groups of `device_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averagePredictions(preds, ids, label=None):\n",
    "    df = pd.DataFrame(preds)\n",
    "    df.columns = enc_group.inverse_transform(df.columns)\n",
    "    df[\"device_id\"] = ids\n",
    "    if not label == None:\n",
    "        df[\"group\"] = label\n",
    "    df = df.groupby(\"device_id\", sort=False, as_index=False).agg(np.mean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As the total sum of our predictions do not need to add up to 1, we don't have to worry about normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "av_pred_val = averagePredictions(probs_lr_val,x_val.device_id.values, x_val.group.values)\n",
    "av_pred_train = averagePredictions(probs_lr_train,x_train.device_id.values, x_train.group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.07042975619\n",
      "Log loss on test set:  2.03019174585\n"
     ]
    }
   ],
   "source": [
    "printLoss(av_pred_train.group, av_pred_train.drop(train_drop,axis=1).as_matrix()\n",
    "          , av_pred_val.group, av_pred_val.drop(train_drop,axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final logistic regression mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainedModels/lr_evts_nEvtsWoLatLong.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"trainedModels/lr_evts_nEvtsWoLatLong.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict actual test devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_test = lr.predict_proba(lr_enc.transform(test.drop([\"device_id\",\"latitude\",\"longitude\"],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av_probs_test = averagePredictions(probs_test\n",
    "                                   , test.device_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av_probs_test.to_csv(\"finalOutputs/lr_Evts_woLatLong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt = GradientBoostingClassifier(loss='deviance'\n",
    "                                  ,max_features=None\n",
    "                                  , min_samples_leaf=800\n",
    "                                  , learning_rate=0.01\n",
    "                                  , n_estimators=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt = joblib.load(\"trainedModels/gbdt_evts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting done in  62.727684278041124  minutes.\n"
     ]
    }
   ],
   "source": [
    "s=time.time()/60.0\n",
    "gbdt.fit(x_train.drop(train_drop,axis=1),y_train)\n",
    "print(\"gradient boosting done in \", (time.time()/60.0)-s, \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_gbdt_test = gbdt.predict_proba(test.drop([\"device_id\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_gbdt_val = gbdt.predict_proba(x_val.drop(train_drop,axis=1))\n",
    "p_gbdt_train = gbdt.predict_proba(x_train.drop(train_drop,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  1.9056459881\n",
      "Log loss on test set:  1.90565042031\n"
     ]
    }
   ],
   "source": [
    "printLoss(y_val,p_gbdt_val, y_train, p_gbdt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "av_val = averagePredictions(p_gbdt_val, x_val.device_id.values, x_val.group.values)\n",
    "av_train = averagePredictions(p_gbdt_train, x_train.device_id.values, x_train.group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.29086334479\n",
      "Log loss on test set:  2.28474007692\n"
     ]
    }
   ],
   "source": [
    "printLoss(av_train.group, av_train.drop(train_drop,axis=1).as_matrix()\n",
    "          , av_val.group, av_val.drop(train_drop,axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This screams for optimisation... for now, we can go with the logreg solution."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
