{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import (LabelEncoder, OneHotEncoder\n",
    "                                   , RobustScaler, StandardScaler)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sys.path.append(\"/home/mschlupp/pythonTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"files/finalSets/apps_full.csv\", nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueLabel</th>\n",
       "      <th>device_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>usageDay</th>\n",
       "      <th>isTrain</th>\n",
       "      <th>group</th>\n",
       "      <th>nActiveApps</th>\n",
       "      <th>nInstallApps</th>\n",
       "      <th>device_model</th>\n",
       "      <th>nEvts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>-2.075058</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.018037</td>\n",
       "      <td>-0.293883</td>\n",
       "      <td>367</td>\n",
       "      <td>-0.139568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>-2.075058</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.018037</td>\n",
       "      <td>-0.293883</td>\n",
       "      <td>367</td>\n",
       "      <td>-0.139568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>-2.075058</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.018037</td>\n",
       "      <td>-0.293883</td>\n",
       "      <td>367</td>\n",
       "      <td>-0.139568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>-2.075058</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.018037</td>\n",
       "      <td>-0.293883</td>\n",
       "      <td>367</td>\n",
       "      <td>-0.139568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>-2.075058</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.018037</td>\n",
       "      <td>-0.293883</td>\n",
       "      <td>367</td>\n",
       "      <td>-0.139568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueLabel            device_id      hour  usageDay  isTrain  group  \\\n",
       "0            6 -6401643145415154744 -2.075058         3        0     12   \n",
       "1            5 -6401643145415154744 -2.075058         3        0     12   \n",
       "2            6 -6401643145415154744 -2.075058         3        0     12   \n",
       "3           13 -6401643145415154744 -2.075058         3        0     12   \n",
       "4           18 -6401643145415154744 -2.075058         3        0     12   \n",
       "\n",
       "   nActiveApps  nInstallApps  device_model     nEvts  \n",
       "0    -1.018037     -0.293883           367 -0.139568  \n",
       "1    -1.018037     -0.293883           367 -0.139568  \n",
       "2    -1.018037     -0.293883           367 -0.139568  \n",
       "3    -1.018037     -0.293883           367 -0.139568  \n",
       "4    -1.018037     -0.293883           367 -0.139568  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to use in the model\n",
    "* categories: [`event_id`, `UniqueLabel`, `usageDay`, `phone_brand`, `device_model`, `nCats`]\n",
    "   * this results in memory issues (too many dimensions)\n",
    "   * drop `event_id`, `nCats`, `phone_brand`\n",
    "* `hour`\n",
    "* `nInstallApps`\n",
    "* `nActiveApps`\n",
    "* `nEvts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [\"UniqueLabel\", \"device_id\",\"hour\",\"usageDay\",\"isTrain\",\"group\"\n",
    "        ,\"nActiveApps\",\"nInstallApps\",\"device_model\",\"nEvts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"files/finalSets/apps_full.csv\", usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler_nAct = StandardScaler()\n",
    "scaler_nInst = StandardScaler()\n",
    "scaler_hour = StandardScaler()\n",
    "scaler_nevts = StandardScaler()\n",
    "data[\"nActiveApps\"] = scaler_nAct.fit_transform(data.nActiveApps.reshape(-1, 1))\n",
    "data[\"nEvts\"] = scaler_nevts.fit_transform(data.nEvts.reshape(-1, 1))\n",
    "data[\"nInstallApps\"] = scaler_nInst.fit_transform(data.nInstallApps.reshape(-1, 1))\n",
    "data[\"hour\"] = scaler_hour.fit_transform(data.hour.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model done.\n",
      "group done.\n",
      "label done.\n"
     ]
    }
   ],
   "source": [
    "#enc_brand = LabelEncoder()\n",
    "enc_device = LabelEncoder()\n",
    "enc_group = LabelEncoder()\n",
    "enc_label = LabelEncoder()\n",
    "#data[\"phone_brand\"] = enc_brand.fit_transform(data.phone_brand)\n",
    "#print(\"brand done.\")\n",
    "data[\"device_model\"] = enc_device.fit_transform(data.device_model)\n",
    "print(\"model done.\")\n",
    "data[\"group\"] = enc_group.fit_transform(data.group)\n",
    "print(\"group done.\")\n",
    "data[\"UniqueLabel\"] = enc_label.fit_transform(data.UniqueLabel)\n",
    "print(\"label done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UniqueLabel', 'hour', 'usageDay', 'nActiveApps', 'nInstallApps',\n",
       "       'device_model', 'nEvts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop([\"isTrain\",\"device_id\",\"group\"], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_enc = OneHotEncoder(categorical_features=[0,2,5])\n",
    "#lr_enc.fit(data.drop([\"isTrain\",\"device_id\",\"group\"],axis=1))\n",
    "lr_enc = joblib.load(\"OneHotEncoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(lr_enc, \"OneHotEncoder.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_list = [\"isTrain\"]\n",
    "train = data[data.isTrain==1].drop( drop_list, axis=1)\n",
    "true_classes = train.group\n",
    "test = data[data.isTrain==0].drop( drop_list+[\"group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train\n",
    "                                                   , true_classes, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_drop = [\"group\",\"device_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1'\n",
    "                        , C=0.5 \n",
    "                        , tol=0.00001 # was 0.0001\n",
    "                        , solver=\"liblinear\" #'lbfgs'\n",
    "                        , max_iter=900\n",
    "                        , warm_start=True\n",
    "                        #, multi_class='multinomial'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.fit(lr_enc.transform(x_train.drop(train_drop,axis=1)),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainedModels/lr_App_first.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"trainedModels/lr_App_first.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss):\n",
    "    print(\"Test MVA predictions on test and training set:\\n\")\n",
    "    print(\"Log loss on training set: \", loss(y_tr,p_tr))\n",
    "    print(\"Log loss on test set: \", loss(y_te,p_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_lr_train = lr.predict_proba(lr_enc.transform(x_train.drop(train_drop,axis=1)))\n",
    "probs_lr_test = lr.predict_proba(lr_enc.transform(x_test.drop(train_drop,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  1.96650679674\n",
      "Log loss on test set:  1.96661161514\n"
     ]
    }
   ],
   "source": [
    "printLoss(y_train, probs_lr_train, y_test, probs_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averagePredictions(preds, ids, label=None):\n",
    "    df = pd.DataFrame(preds)\n",
    "    df.columns = enc_group.inverse_transform(df.columns)\n",
    "    df[\"device_id\"] = ids\n",
    "    if not label == None:\n",
    "        df[\"group\"] = label\n",
    "    df = df.groupby(\"device_id\", sort=False, as_index=False).agg(np.mean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "av_pred_val = averagePredictions(probs_lr_test,x_test.device_id.values, x_test.group.values)\n",
    "av_pred_train = averagePredictions(probs_lr_train,x_train.device_id.values, x_train.group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.36184578646\n",
      "Log loss on test set:  2.36182222885\n"
     ]
    }
   ],
   "source": [
    "printLoss(av_pred_train.group, av_pred_train.drop(train_drop,axis=1).as_matrix()\n",
    "          , av_pred_val.group, av_pred_val.drop(train_drop,axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try other models w/o much encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.fit(x_train.drop(train_drop,axis=1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=600, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=1e-05, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.31551493378\n",
      "Log loss on test set:  2.31622721104\n"
     ]
    }
   ],
   "source": [
    "probs_lr_train = lr.predict_proba(x_train.drop(train_drop,axis=1))\n",
    "probs_lr_test = lr.predict_proba(x_test.drop(train_drop,axis=1))\n",
    "printLoss(y_train, probs_lr_train, y_test, probs_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.4042400584\n",
      "Log loss on test set:  2.40374309803\n"
     ]
    }
   ],
   "source": [
    "av_pred_val = averagePredictions(probs_lr_test,x_test.device_id.values, x_test.group.values)\n",
    "av_pred_train = averagePredictions(probs_lr_train,x_train.device_id.values, x_train.group.values)\n",
    "printLoss(av_pred_train.group, av_pred_train.drop(train_drop,axis=1).as_matrix()\n",
    "          , av_pred_val.group, av_pred_val.drop(train_drop,axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_classes_nn = x_train.group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we would like to use the categorical_crossentropy (multiclass logloss)\n",
    "# so let's convert classes to categroies\n",
    "from keras.utils.np_utils import to_categorical\n",
    "true_classes_nn = to_categorical(true_classes_nn)\n",
    "# true_classes now is a binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.drop(train_drop,axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in keras we need to build models.\n",
    "# we build our own sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# first we add a dense layer (std NN layer)\n",
    "# we need an output of 12 dimensions\n",
    "model.add(Dense(output_dim=30, input_dim=7))\n",
    "model.add(Activation(\"tanh\")) # no real motivation for relu here\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(output_dim=30, activation=\"tanh\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(output_dim=23, activation=\"tanh\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(output_dim=17, activation=\"tanh\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(output_dim=12))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we need to configure the learning process\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "              ,optimizer = \"adadelta\" \n",
    "              #optimizer='adam'\n",
    "              , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "model.fit(x_train.drop(train_drop,axis=1).as_matrix(),true_classes_nn\n",
    "         , verbose=1,nb_epoch=20)\n",
    "print(\"NN trained in \", (time.time()-s)/60.0, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(in_data.as_matrix(), true_classes_nn)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
