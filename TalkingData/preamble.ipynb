{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersec(d1, d2):\n",
    "    return list(set(d1).intersection(set(d2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union(d1,d2):\n",
    "    return list(set(d1).union(set(d2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consistent(d1,d2,train,test):\n",
    "    int_d12_train = intersec(d1[d1.isTrain==1].device_id.values\n",
    "                             ,d2[d2.isTrain==1].device_id.values)\n",
    "    int_d12_test = intersec(d1[d1.isTrain==0].device_id.values\n",
    "                            ,d2[d2.isTrain==0].device_id.values)\n",
    "\n",
    "    un_d12_train = union(d1[d1.isTrain==1].device_id.unique()\n",
    "                         ,d2[d2.isTrain==1].device_id.unique())\n",
    "    un_d12_test = union(d1[d1.isTrain==0].device_id.unique()\n",
    "                        ,d2[d2.isTrain==0].device_id.unique())\n",
    "\n",
    "    print(\"len uniques ids: d1\", len(d1.device_id.unique()), \" d2: \"\n",
    "          , len(d2.device_id.unique()))\n",
    "    print(\"sum: \", len(d1.device_id.unique())+len(d2.device_id.unique()))\n",
    "    print(\"\")\n",
    "    print(\"intersection of d1 and d2: \", len(intersec(d1.device_id.values\n",
    "                                                      ,d2.device_id.values)))\n",
    "    print(\"\")\n",
    "    print(\"Unique train in d1 and d2: \", len(un_d12_train))\n",
    "    print(\"Unique test in d1 and d2: \", len(un_d12_test))\n",
    "    print(\"\")\n",
    "    print(\"intersec of train ids in both sets: \", len(intersec(un_d12_train,train)))\n",
    "    print(\"intersec of test ids in both sets: \", len(intersec(un_d12_test,test)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xcheckData(data):\n",
    "    print(\"len: \",len(data))\n",
    "    print(\"len train: \", len(data[data.isTrain==1]))\n",
    "    print(\"len test: \", len(data[data.isTrain==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preamble handles a few imports and defines the following functions:\n",
      "\n",
      "printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss)\n",
      "createDataSet(predictions, group_encoder, device_ids)\n",
      "getBestPrediction(data,var='device_id')\n",
      "\n",
      "\n",
      "A few Debug functions\n"
     ]
    }
   ],
   "source": [
    "print(\"The preamble handles a few imports and defines the following functions:\\n\")\n",
    "print(\"printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss)\")\n",
    "print(\"createDataSet(predictions, group_encoder, device_ids)\")\n",
    "\n",
    "print(\"getBestPrediction(data,var='device_id')\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"A few Debug functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet(predictions, group_encoder, device_ids):\n",
    "    \"\"\"\n",
    "    Creates prediction dataset to save into csv from \n",
    "    multiclass predictions (ndarray).\n",
    "    \n",
    "    Arguments:\n",
    "    predictions   - (ndarray) predictions from the MVA.\n",
    "    group_encoder - (LabelEncoder) to transform column names.\n",
    "    device_ids    - (pd.Series, array...) respective device_ids.\n",
    "    \"\"\"\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.columns = group_encoder.inverse_transform(predictions.columns)\n",
    "    predictions[\"device_id\"] = device_ids\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss):\n",
    "    \"\"\"\n",
    "    Function prints loss value for up to two datasets\n",
    "    for a given loss function (default: log_loss)\n",
    "    \n",
    "    y_tr - (true) classes of training set (or single set).\n",
    "    p_tr - predictions of training set (or single set).\n",
    "    y_te - (true) classes of second set.\n",
    "    p_te - predictions of the second set.\n",
    "    loss - loss function.\n",
    "    \"\"\"\n",
    "    print(\"Test MVA predictions on test and training set:\\n\")\n",
    "    print(\"Log loss on training set: \", loss(y_tr,p_tr))\n",
    "    print(\"Log loss on test set: \", loss(y_te,p_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBestPrediction(data,var=\"device_id\"):\n",
    "    \"\"\"\n",
    "    Function that returns data set with \n",
    "    unique `var` entries that satisfy:\n",
    "    highest prediction probability for \n",
    "    the class with highest mean prediction.\n",
    "    \n",
    "    Arguments:\n",
    "    data  - (pd.DataFrame) The dataset to work with\n",
    "    var   - (str) Feature to find uniques\n",
    "    \"\"\"\n",
    "    gb = data.groupby(var, as_index=False, sort=False)\n",
    "    indeces = list()\n",
    "    for i,g in enumerate(gb.groups):\n",
    "        # this searches class with highest mean prediction\n",
    "        most_likely_class= gb.get_group(g).drop(var,axis=1)\\\n",
    "                                 .mean()\\\n",
    "                                 .sort_values(ascending=False)\\\n",
    "                                 .index[0]\n",
    "\n",
    "        # this searches prediction with highest probability in most likely class\n",
    "\n",
    "        index = gb.get_group(g).drop(var,axis=1)[most_likely_class]\\\n",
    "                                     .sort_values(ascending=False)\\\n",
    "                                     .index[0]\n",
    "        \n",
    "        indeces.append(index)\n",
    "        \n",
    "        if i%3000==0 and i>0:\n",
    "            print(i+1, \"/\", len(gb.groups), \" groups processed...\")\n",
    "    \n",
    "                \n",
    "    return data.iloc[indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averagePredictions(preds):\n",
    "    return preds.groupby(\"device_id\", sort=False, as_index=False).agg(np.mean)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupnote]",
   "language": "python",
   "name": "conda-env-jupnote-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
