{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## The preamble handles a few imports.\n",
       "## It also loads common functions and dicts: \n",
       "\n",
       "## Bosch challenge specific:\n",
       "* **getMCC**(tp,tn,fp,fn)\n",
       "\n",
       "## ML/Analytics functions:\n",
       "* **compare_train_test**(clf, ds_train, label_train, ds_test, label_test, mva='MVA', bins=50, use_vote=None, log=False)\n",
       "* **plot_classifier_output**( pred_train, pred_test, y_train, y_test, multipagepdf=None, bins = None, normalised = True )\n",
       "* **plot_correlations**(data,label='', \\*\\*kwds)\n",
       "* **optimisePars**(mva, points, data , classes, fraction=0.7, score = 'log_loss', cvs=5)\n",
       "\n",
       "---\n",
       "\n",
       "## Various\n",
       "* **showUniques**(df)\n",
       "* **ensure_dir**(directory)\n",
       "* **printBumper**(text, c='=', n=-1)\n",
       "* **intersec**(d1, d2)\n",
       "* **union**(d1, d2)\n",
       "\n",
       "---\n",
       "\n",
       "## Color dictionaries:\n",
       "* **Tableau10**\n",
       "* **Tableau10_Light**\n",
       "* **Tableau10_Medium**\n",
       "* **Tableau_20**\n",
       "* **ColorBlind10**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run preamble.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "## Group data into stations\n",
    "In this way we have logical packages of data w/o too many NaNs.\n",
    "\n",
    "## Unsupervised dimensionalty reduction using PCA\n",
    "This should result in better and most importantly less variables.\n",
    "Then choose best six with an ANOVA filter.\n",
    "\n",
    "## Supervised predictions using a BDT \n",
    "Use BDT on 6 (or less) variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"files/train_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addLineStation(ds):\n",
    "    l0=[]\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for c in ds:\n",
    "        s = c.split(sep=\"_\")\n",
    "        l0.append(s[0])\n",
    "        l1.append(s[0]+\"_\"+s[1])\n",
    "        l2.append(c)\n",
    "    return pd.MultiIndex.from_arrays([l0,l1,l2],names=[\"Line\",\"Station\",\"Feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a little bit of index magic to be able to group by station\n",
    "train = train.set_index([\"Id\",\"Response\"])\n",
    "traindrop = [\"Id\",\"Response\"]\n",
    "train.columns = addLineStation(train)\n",
    "\n",
    "gb = train.groupby(level=\"Station\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainMVA(grps, processed=[], save=False):\n",
    "    mvas = {}\n",
    "    for i,g in enumerate(grps.groups):\n",
    "        s=time.time()\n",
    "        if g in processed:\n",
    "            print(g, \" already trained. Continue.\")\n",
    "            continue\n",
    "        if i%10==0 and i>0 and save:\n",
    "            print(\"pickle intermediate results at i=\",i)\n",
    "            joblib.dump(mvas,\"files/mvas_per_station{}.pkl\".format(i)\n",
    "                        , compress = 3)\n",
    "            mvas={}\n",
    "        # Dataset magic\n",
    "        d = gb.get_group(g).dropna(how=\"all\", axis=0)\n",
    "        d.columns = d.columns.droplevel([\"Line\",\"Station\"])\n",
    "        d=d.reset_index()\n",
    "    \n",
    "        n_features = len(d.columns)-2\n",
    "        \n",
    "        n_pca = 10 if n_features>10 else n_features\n",
    "        n_annova = 6 if n_pca>6 else n_pca\n",
    "        n_max_feat_bdt = 4 if n_annova==6 else n_annova\n",
    "    \n",
    "        # filter\n",
    "        # feature selection\n",
    "        anova_filter = SelectKBest(f_classif, k=n_annova)\n",
    "    \n",
    "        # classifier\n",
    "        bdt = AdaBoostClassifier(DecisionTreeClassifier(max_features=n_max_feat_bdt\n",
    "                                                        , max_depth=3)\n",
    "                        , n_estimators = 600\n",
    "                        , learning_rate = 0.01)\n",
    "        # pipeline\n",
    "        print(\"classifier pipeline fit for goup: \"\n",
    "              , g, \"(\",i+1,\"/\",len(gb.groups),\")\")\n",
    "        clf = Pipeline([(\"fillVals\", Imputer(strategy=\"mean\",verbose=1))\n",
    "                ,(\"dimReduction\", PCA(n_components=n_pca))\n",
    "                ,('feature_selection', anova_filter)\n",
    "                ,('mva', bdt)])\n",
    "    \n",
    "        clf.fit(d.drop(traindrop,axis=1), d.Response)\n",
    "        print(\"done in {:2.2f}\".format((time.time()-s)/60.),\" minutes.\")\n",
    "        mvas[g] = clf\n",
    "        del d\n",
    "    joblib.dump(mvas,\"files/mvas_per_station{}.pkl\".format(len(grps.groups)+1)\n",
    "                , compress = 3)        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0_S23  already trained. Continue.\n",
      "L3_S50  already trained. Continue.\n",
      "L3_S41  already trained. Continue.\n",
      "L3_S35  already trained. Continue.\n",
      "L0_S11  already trained. Continue.\n",
      "L2_S27  already trained. Continue.\n",
      "L0_S9  already trained. Continue.\n",
      "L3_S45  already trained. Continue.\n",
      "L0_S8  already trained. Continue.\n",
      "L3_S33  already trained. Continue.\n",
      "L3_S37  already trained. Continue.\n",
      "L3_S43  already trained. Continue.\n",
      "L0_S16  already trained. Continue.\n",
      "L3_S39  already trained. Continue.\n",
      "L0_S14  already trained. Continue.\n",
      "L0_S15  already trained. Continue.\n",
      "L3_S47  already trained. Continue.\n",
      "L0_S17  already trained. Continue.\n",
      "L3_S32  already trained. Continue.\n",
      "L0_S18  already trained. Continue.\n",
      "L0_S0  already trained. Continue.\n",
      "L3_S48  already trained. Continue.\n",
      "L0_S22  already trained. Continue.\n",
      "L0_S6  already trained. Continue.\n",
      "L0_S5  already trained. Continue.\n",
      "L3_S30  already trained. Continue.\n",
      "L0_S19  already trained. Continue.\n",
      "L2_S28  already trained. Continue.\n",
      "L3_S49  already trained. Continue.\n",
      "L0_S13  already trained. Continue.\n",
      "L0_S2  already trained. Continue.\n",
      "L3_S36  already trained. Continue.\n",
      "L2_S26  already trained. Continue.\n",
      "L3_S34  already trained. Continue.\n",
      "L3_S51  already trained. Continue.\n",
      "L0_S7  already trained. Continue.\n",
      "L1_S24  already trained. Continue.\n",
      "L0_S10  already trained. Continue.\n",
      "L3_S38  already trained. Continue.\n",
      "L0_S1  already trained. Continue.\n",
      "classifier pipeline fit for goup:  L3_S31 ( 41 / 50 )\n",
      "done in 0.38  minutes.\n",
      "classifier pipeline fit for goup:  L0_S12 ( 42 / 50 )\n",
      "done in 8.16  minutes.\n",
      "classifier pipeline fit for goup:  L0_S21 ( 43 / 50 )\n",
      "done in 2.48  minutes.\n",
      "L0_S20  already trained. Continue.\n",
      "L3_S44  already trained. Continue.\n",
      "classifier pipeline fit for goup:  L3_S29 ( 46 / 50 )\n",
      "done in 50.78  minutes.\n",
      "L0_S4  already trained. Continue.\n",
      "classifier pipeline fit for goup:  L3_S40 ( 48 / 50 )\n",
      "done in 1.53  minutes.\n",
      "L1_S25  already trained. Continue.\n",
      "L0_S3  already trained. Continue.\n",
      "Wall time: 1h 3min 22s\n"
     ]
    }
   ],
   "source": [
    "# do all the heavy lifting!\n",
    "%time trainMVA(gb,trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = joblib.load(\"files/mvas_per_station.pkl\")\n",
    "trained.update(joblib.load(\"files/mvas_per_station10.pkl\"))\n",
    "trained.update(joblib.load(\"files/mvas_per_station20.pkl\"))\n",
    "trained.update(joblib.load(\"files/mvas_per_station30.pkl\"))\n",
    "trained.update(joblib.load(\"files/mvas_per_station40.pkl\"))\n",
    "trained.update(joblib.load(\"files/mvas_per_station50.pkl\"))\n",
    "trained.update(joblib.load(\"files/mvas_per_station51.pkl\"))\n",
    "\n",
    "# run again to get all (small coding bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0_S23  already trained. Continue.\n",
      "L3_S50  already trained. Continue.\n",
      "L3_S41  already trained. Continue.\n",
      "L3_S35  already trained. Continue.\n",
      "L0_S11  already trained. Continue.\n",
      "L2_S27  already trained. Continue.\n",
      "L0_S9  already trained. Continue.\n",
      "L3_S45  already trained. Continue.\n",
      "L0_S8  already trained. Continue.\n",
      "L3_S33  already trained. Continue.\n",
      "L3_S37  already trained. Continue.\n",
      "L3_S43  already trained. Continue.\n",
      "L0_S16  already trained. Continue.\n",
      "L3_S39  already trained. Continue.\n",
      "L0_S14  already trained. Continue.\n",
      "L0_S15  already trained. Continue.\n",
      "L3_S47  already trained. Continue.\n",
      "L0_S17  already trained. Continue.\n",
      "L3_S32  already trained. Continue.\n",
      "L0_S18  already trained. Continue.\n",
      "L0_S0  already trained. Continue.\n",
      "L3_S48  already trained. Continue.\n",
      "L0_S22  already trained. Continue.\n",
      "L0_S6  already trained. Continue.\n",
      "L0_S5  already trained. Continue.\n",
      "L3_S30  already trained. Continue.\n",
      "L0_S19  already trained. Continue.\n",
      "L2_S28  already trained. Continue.\n",
      "L3_S49  already trained. Continue.\n",
      "L0_S13  already trained. Continue.\n",
      "classifier pipeline fit for goup:  L0_S2 ( 31 / 50 )\n",
      "done in 11.82  minutes.\n",
      "classifier pipeline fit for goup:  L3_S36 ( 32 / 50 )\n",
      "done in 9.82  minutes.\n",
      "classifier pipeline fit for goup:  L2_S26 ( 33 / 50 )\n",
      "done in 7.68  minutes.\n",
      "classifier pipeline fit for goup:  L3_S34 ( 34 / 50 )\n",
      "done in 8.30  minutes.\n",
      "classifier pipeline fit for goup:  L3_S51 ( 35 / 50 )\n",
      "done in 0.34  minutes.\n",
      "classifier pipeline fit for goup:  L0_S7 ( 36 / 50 )\n",
      "done in 7.13  minutes.\n",
      "classifier pipeline fit for goup:  L1_S24 ( 37 / 50 )\n",
      "done in 5.44  minutes.\n",
      "L0_S10  already trained. Continue.\n",
      "classifier pipeline fit for goup:  L3_S38 ( 39 / 50 )\n",
      "done in 0.51  minutes.\n",
      "classifier pipeline fit for goup:  L0_S1 ( 40 / 50 )\n",
      "done in 14.10  minutes.\n",
      "L3_S31  already trained. Continue.\n",
      "L0_S12  already trained. Continue.\n",
      "L0_S21  already trained. Continue.\n",
      "L0_S20  already trained. Continue.\n",
      "L3_S44  already trained. Continue.\n",
      "L3_S29  already trained. Continue.\n",
      "L0_S4  already trained. Continue.\n",
      "L3_S40  already trained. Continue.\n",
      "L1_S25  already trained. Continue.\n",
      "L0_S3  already trained. Continue.\n"
     ]
    }
   ],
   "source": [
    "trainMVA(gb, list(trained.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictStations(grps, mvas, results, processed=[], save=False):\n",
    "    for i,g in enumerate(grps.groups):\n",
    "        s=time.time()\n",
    "        if g in processed:\n",
    "            print(g, \" already predicted. Continue.\")\n",
    "            continue\n",
    "        # Dataset magic\n",
    "        d = gb.get_group(g).dropna(how=\"all\", axis=0)\n",
    "        d.columns = d.columns.droplevel([\"Line\",\"Station\"])\n",
    "        d=d.reset_index()\n",
    "\n",
    "        # pipeline\n",
    "        print(\"classifier pipeline prediction for goup: \"\n",
    "              , g, \"(\",i+1,\"/\",len(gb.groups),\")\")\n",
    "        clf = mvas[g]\n",
    "    \n",
    "        pred_func = pd.DataFrame({\"Id\" : d.Id\n",
    "                            ,\"pred_\"+g :clf.decision_function(d.drop(traindrop,axis=1))})\n",
    "        results = results.merge(pred_func, on=\"Id\", how=\"left\")\n",
    "        print(\"done in {:2.2f}\".format((time.time()-s)/60.),\" minutes.\")\n",
    "        del d\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Id\": train.reset_index()[\"Id\"],\n",
    "                       \"Response\": train.reset_index()[\"Response\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier pipeline prediction for goup:  L0_S23 ( 1 / 50 )\n",
      "done in 0.19  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S50 ( 2 / 50 )\n",
      "done in 0.07  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S41 ( 3 / 50 )\n",
      "done in 0.14  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S35 ( 4 / 50 )\n",
      "done in 1.31  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S11 ( 5 / 50 )\n",
      "done in 0.53  minutes.\n",
      "classifier pipeline prediction for goup:  L2_S27 ( 6 / 50 )\n",
      "done in 0.29  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S9 ( 7 / 50 )\n",
      "done in 0.53  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S45 ( 8 / 50 )\n",
      "done in 0.13  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S8 ( 9 / 50 )\n",
      "done in 1.58  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S33 ( 10 / 50 )\n",
      "done in 2.76  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S37 ( 11 / 50 )\n",
      "done in 2.57  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S43 ( 12 / 50 )\n",
      "done in 0.07  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S16 ( 13 / 50 )\n",
      "done in 0.27  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S39 ( 14 / 50 )\n",
      "done in 0.13  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S14 ( 15 / 50 )\n",
      "done in 0.29  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S15 ( 16 / 50 )\n",
      "done in 0.29  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S47 ( 17 / 50 )\n",
      "done in 0.14  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S17 ( 18 / 50 )\n",
      "done in 0.28  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S32 ( 19 / 50 )\n",
      "done in 0.06  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S18 ( 20 / 50 )\n",
      "done in 0.27  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S0 ( 21 / 50 )\n",
      "done in 1.62  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S48 ( 22 / 50 )\n",
      "done in 0.14  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S22 ( 23 / 50 )\n",
      "done in 0.19  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S6 ( 24 / 50 )\n",
      "done in 0.80  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S5 ( 25 / 50 )\n",
      "done in 0.79  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S30 ( 26 / 50 )\n",
      "done in 2.76  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S19 ( 27 / 50 )\n",
      "done in 0.28  minutes.\n",
      "classifier pipeline prediction for goup:  L2_S28 ( 28 / 50 )\n",
      "done in 0.04  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S49 ( 29 / 50 )\n",
      "done in 0.07  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S13 ( 30 / 50 )\n",
      "done in 0.55  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S2 ( 31 / 50 )\n",
      "done in 0.82  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S36 ( 32 / 50 )\n",
      "done in 1.35  minutes.\n",
      "classifier pipeline prediction for goup:  L2_S26 ( 33 / 50 )\n",
      "done in 0.54  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S34 ( 34 / 50 )\n",
      "done in 2.54  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S51 ( 35 / 50 )\n",
      "done in 0.14  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S7 ( 36 / 50 )\n",
      "done in 0.78  minutes.\n",
      "classifier pipeline prediction for goup:  L1_S24 ( 37 / 50 )\n",
      "done in 0.55  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S10 ( 38 / 50 )\n",
      "done in 0.52  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S38 ( 39 / 50 )\n",
      "done in 0.07  minutes.\n",
      "classifier pipeline prediction for goup:  L0_S1 ( 40 / 50 )\n",
      "done in 1.56  minutes.\n",
      "classifier pipeline prediction for goup:  L3_S31 ( 41 / 50 )\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'L3_S31'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-dc52d004cf6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_functs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictStations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-5d8c4a6f9636>\u001b[0m in \u001b[0;36mpredictStations\u001b[0;34m(grps, mvas, results, processed, save)\u001b[0m\n\u001b[1;32m     13\u001b[0m         print(\"classifier pipeline prediction for goup: \"\n\u001b[1;32m     14\u001b[0m               , g, \"(\",i+1,\"/\",len(gb.groups),\")\")\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         pred_func = pd.DataFrame({\"Id\" : d.Id\n",
      "\u001b[0;31mKeyError\u001b[0m: 'L3_S31'"
     ]
    }
   ],
   "source": [
    "pre_functs = predictStations(gb, trained, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pred_L0_S23</th>\n",
       "      <th>pred_L3_S50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41</td>\n",
       "      <td>-1.004551</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47</td>\n",
       "      <td>-1.067508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>-0.972351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>97</td>\n",
       "      <td>-1.306680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>124</td>\n",
       "      <td>-1.062109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  pred_L0_S23  pred_L3_S50\n",
       "16   41    -1.004551          NaN\n",
       "18   47    -1.067508          NaN\n",
       "21   55    -0.972351          NaN\n",
       "45   97    -1.306680          NaN\n",
       "60  124    -1.062109          NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_functs[~pre_functs.pred_L0_S23.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mvas=joblib.load(\"files/mvas_per_station.pkl\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupnote]",
   "language": "python",
   "name": "conda-env-jupnote-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
