{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## The preamble handles a few imports.\n",
       "## It also loads common functions and dicts: \n",
       "\n",
       "## Bosch challenge specific:\n",
       "* **getMCC**(tp,tn,fp,fn)\n",
       "\n",
       "## ML/Analytics functions:\n",
       "* **compare_train_test**(clf, ds_train, label_train, ds_test, label_test, mva='MVA', bins=50, use_vote=None, log=False)\n",
       "* **plot_classifier_output**( pred_train, pred_test, y_train, y_test, multipagepdf=None, bins = None, normalised = True )\n",
       "* **plot_correlations**(data,label='', \\*\\*kwds)\n",
       "* **optimisePars**(mva, points, data , classes, fraction=0.7, score = 'log_loss', cvs=5)\n",
       "\n",
       "---\n",
       "\n",
       "## Various\n",
       "* **showUniques**(df)\n",
       "* **ensure_dir**(directory)\n",
       "* **printBumper**(text, c='=', n=-1)\n",
       "* **intersec**(d1, d2)\n",
       "* **union**(d1, d2)\n",
       "\n",
       "---\n",
       "\n",
       "## Color dictionaries:\n",
       "* **Tableau10**\n",
       "* **Tableau10_Light**\n",
       "* **Tableau10_Medium**\n",
       "* **Tableau_20**\n",
       "* **ColorBlind10**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run preamble.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "## Group data into stations\n",
    "In this way we have logical packages of data w/o too many NaNs.\n",
    "\n",
    "## Unsupervised dimensionalty reduction using PCA\n",
    "This should result in better and most importantly less variables.\n",
    "Then choose best six with an ANOVA filter.\n",
    "\n",
    "## Supervised predictions using a BDT \n",
    "Use BDT on 6 (or less) variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"files/train_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addLineStation(ds):\n",
    "    l0=[]\n",
    "    l1=[]\n",
    "    l2=[]\n",
    "    for c in ds:\n",
    "        s = c.split(sep=\"_\")\n",
    "        l0.append(s[0])\n",
    "        l1.append(s[0]+\"_\"+s[1])\n",
    "        l2.append(c)\n",
    "    return pd.MultiIndex.from_arrays([l0,l1,l2],names=[\"Line\",\"Station\",\"Feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a little bit of index magic to be able to group by station\n",
    "train = train.set_index([\"Id\",\"Response\"])\n",
    "traindrop = [\"Id\",\"Response\"]\n",
    "train.columns = addLineStation(train)\n",
    "\n",
    "gb = train.groupby(level=\"Station\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainMVA(grps):\n",
    "    mvas = {}\n",
    "    for i,g in enumerate(grps.groups):\n",
    "        s=time.time()\n",
    "        if i%10==0 and i>0:\n",
    "            print(\"pickle intermediate results at i=\",i)\n",
    "            joblib.dump(mvas,\"files/mvas_per_station{}.pkl\".format(i))\n",
    "            mvas={}\n",
    "        # Dataset magic\n",
    "        d = gb.get_group(g).dropna(how=\"all\", axis=0)\n",
    "        d.columns = d.columns.droplevel([\"Line\",\"Station\"])\n",
    "        d=d.reset_index()\n",
    "    \n",
    "        n_features = len(d.columns)-2\n",
    "        \n",
    "        n_pca = 10 if n_features>10 else n_features\n",
    "        n_annova = 6 if n_pca>6 else n_pca\n",
    "        n_max_feat_bdt = 4 if n_annova==6 else n_annova\n",
    "    \n",
    "        # filter\n",
    "        # feature selection\n",
    "        anova_filter = SelectKBest(f_classif, k=n_annova)\n",
    "    \n",
    "        # classifier\n",
    "        bdt = AdaBoostClassifier(DecisionTreeClassifier(max_features=n_max_feat_bdt\n",
    "                                                        , max_depth=3)\n",
    "                        , n_estimators = 600\n",
    "                        , learning_rate = 0.01)\n",
    "        # pipeline\n",
    "        clf = Pipeline([(\"fillVals\", Imputer(strategy=\"mean\",verbose=1))\n",
    "                ,(\"dimReduction\", PCA(n_components=n_pca))\n",
    "                ,('feature_selection', anova_filter)\n",
    "                ,('mva', bdt)])\n",
    "    \n",
    "        clf.fit(d.drop(traindrop,axis=1), d.Response)\n",
    "        print(\"classifier pipeline fit for goup: \"\n",
    "              , g, \"(\",i+1,\"/\",len(gb.groups),\")\")\n",
    "        print(\"done in {:2.2f}\".format((time.time()-s)/60.),\" minutes.\")\n",
    "        mvas[g] = clf\n",
    "        del d\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier pipeline fit for goup:  L3_S32 ( 1 / 50 )\n",
      "done in 0.21  minutes.\n"
     ]
    }
   ],
   "source": [
    "# do all the heavy lifting!\n",
    "%time trainMVA(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the hard work!\n",
    "joblib.dump(mvas, \"files/mvas_per_station.pkl\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mvas=joblib.load(\"files/mvas_per_station.pkl\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupnote]",
   "language": "python",
   "name": "conda-env-jupnote-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
