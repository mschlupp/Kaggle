{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preamble handles a few imports and defines the following functions:\n",
      "\n",
      "printLoss(y_tr,p_tr,y_te,p_te,loss=log_loss)\n",
      "createDataSet(predictions, group_encoder, device_ids)\n",
      "getBestPrediction(data,var='device_id')\n",
      "\n",
      "\n",
      "A few Debug functions\n"
     ]
    }
   ],
   "source": [
    "%run preamble.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model variables\n",
    "We'll build our model based on:\n",
    "* `device_model`\n",
    "* `phone_brand`\n",
    "* `usageDay`\n",
    "* `hour`\n",
    "* `nEvts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"files/finalSets/evts_noApp_phone.csv\")\n",
    "data = data.drop([\"event_id\",\"longitude\",\"latitude\",\"day\",\"time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device_id', 'hour', 'usageDay', 'isTrain', 'group', 'phone_brand',\n",
       "       'device_model', 'nEvts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_drop = [\"group\",\"device_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'float'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_brand = LabelEncoder()\n",
    "enc_device = LabelEncoder()\n",
    "enc_group = LabelEncoder()\n",
    "data[\"phone_brand\"] = enc_brand.fit_transform(data.phone_brand)\n",
    "data[\"device_model\"] = enc_device.fit_transform(data.device_model)\n",
    "data[\"group\"] = enc_group.fit_transform(data.group)\n",
    "\n",
    "#scaler_long = RobustScaler()\n",
    "#scaler_lat = RobustScaler()\n",
    "#scaler_nevts = RobustScaler()\n",
    "#data[\"latitude\"] = scaler_lat.fit_transform(data.latitude.reshape(-1,1))\n",
    "#data[\"longitude\"] = scaler_long.fit_transform(data.longitude.reshape(-1,1))\n",
    "#data[\"nEvts\"] = scaler_nevts.fit_transform(data.nEvts.reshape(-1,1))\n",
    "\n",
    "lr_enc = OneHotEncoder()#categorical_features=[0,1,2,3,4])\n",
    "lr_enc.fit(data.drop(train_drop+[\"isTrain\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>usageDay</th>\n",
       "      <th>isTrain</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>nEvts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>426</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  hour  usageDay  isTrain  group  phone_brand  \\\n",
       "0    29182687948017175     0         3        1     11            0   \n",
       "1 -4833982096941402721     0         3        1     11            0   \n",
       "\n",
       "   device_model  nEvts  \n",
       "0           143    256  \n",
       "1           426    248  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_list = [\"isTrain\"]\n",
    "train = data[data.isTrain==1].drop( drop_list, axis=1)\n",
    "true_classes = train.group\n",
    "test = data[data.isTrain==0].drop( drop_list+[\"group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train\n",
    "                                                  , true_classes\n",
    "                                                  , test_size=0.3\n",
    "                                                  , random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device_id', 'hour', 'usageDay', 'group', 'phone_brand', 'device_model',\n",
       "       'nEvts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model: linear logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = joblib.load(\"trainedModels/lr_evts_nEvtsWoLatLong.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2'\n",
    "                        , C=0.4 # was 0.05\n",
    "                        , tol=0.001 # was 0.0001\n",
    "                        , solver='lbfgs'\n",
    "                        , max_iter=300\n",
    "                        #, warm_start=True\n",
    "                        , multi_class='multinomial'\n",
    "                        , verbose =1\n",
    "                        , n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9555771946907043  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 out of   1 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "s=time.time()\n",
    "lr.fit(lr_enc.transform(x_train.drop(train_drop,axis=1)),y_train)\n",
    "print((time.time()-s)/60.0, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  0.977170403555\n",
      "Log loss on test set:  0.987642916307\n"
     ]
    }
   ],
   "source": [
    "probs_lr_train = lr.predict_proba(lr_enc.transform(x_train.drop(train_drop,axis=1)))\n",
    "probs_lr_val = lr.predict_proba(lr_enc.transform(x_val.drop(train_drop,axis=1)))\n",
    "\n",
    "printLoss(y_train, probs_lr_train, y_val, probs_lr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainedModels/lr_evts_nEvtsWoLatLong_LargeC04.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"trainedModels/lr_evts_nEvtsWoLatLong_LargeC04.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* c04_t0.001: 0.987 test (vs 0.977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs_lr_train = createDataSet(probs_lr_train, enc_group, x_train.device_id.values)\n",
    "\n",
    "probs_lr_val = createDataSet(probs_lr_val, enc_group, x_val.device_id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we take the maximum probability of highest mean class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001 / 11002  groups processed...\n",
      "6001 / 11002  groups processed...\n",
      "9001 / 11002  groups processed...\n",
      "3001 / 10070  groups processed...\n",
      "6001 / 10070  groups processed...\n",
      "9001 / 10070  groups processed...\n"
     ]
    }
   ],
   "source": [
    "probs_lr_train = getBestPrediction(probs_lr_train)\n",
    "probs_lr_val = getBestPrediction(probs_lr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.07851596885\n",
      "Log loss on test set:  2.02997305798\n"
     ]
    }
   ],
   "source": [
    "printLoss(y_train.iloc[probs_lr_train.index.values]\n",
    "          , probs_lr_train.drop(\"device_id\",axis=1).as_matrix()\n",
    "          , y_val.iloc[probs_lr_val.index.values]\n",
    "          , probs_lr_val.drop(\"device_id\",axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.030 (test vs train 2.078) C0.4t0l0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict actual test devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_test = lr.predict_proba(lr_enc.transform(test.drop([\"device_id\"],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#av_probs_test = averagePredictions(probs_test\n",
    "#, test.device_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_test = pd.DataFrame(probs_test)\n",
    "probs_test.columns = enc_group.inverse_transform(probs_test.columns.values)\n",
    "probs_test[\"device_id\"] = test.device_id.values\n",
    "probs_test.to_csv(\"finalOutputs/lr_Evts_woLatLong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=270\n",
    "                            , criterion='entropy'\n",
    "                            , min_samples_split=5\n",
    "                            , min_samples_leaf=1\n",
    "                            , max_leaf_nodes=None\n",
    "                            , n_jobs=2\n",
    "                            , random_state=666\n",
    "                            , verbose=1\n",
    "                            #, warm_start=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'usageDay', 'phone_brand', 'device_model', 'nEvts'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.drop(train_drop,axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf done in  3.939246840775013  minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 270 out of 270 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "s=time.time()/60.0\n",
    "rf.fit(x_train.drop(train_drop,axis=1),y_train)\n",
    "print(\"rf done in \", (time.time()/60.0)-s, \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=2)]: Done 270 out of 270 | elapsed:   55.9s finished\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=2)]: Done 270 out of 270 | elapsed:   22.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  0.0834510049296\n",
      "Log loss on test set:  0.182870837665\n"
     ]
    }
   ],
   "source": [
    "probs_rf_train = rf.predict_proba(x_train.drop(train_drop,axis=1))\n",
    "probs_rf_val = rf.predict_proba(x_val.drop(train_drop,axis=1))\n",
    "\n",
    "printLoss(y_train, probs_rf_train, y_val, probs_rf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_rf_train = createDataSet(probs_rf_train, enc_group, x_train.device_id.values)\n",
    "probs_rf_val = createDataSet(probs_rf_val, enc_group, x_val.device_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001 / 11002  groups processed...\n",
      "6001 / 11002  groups processed...\n",
      "9001 / 11002  groups processed...\n",
      "3001 / 10070  groups processed...\n",
      "6001 / 10070  groups processed...\n",
      "9001 / 10070  groups processed...\n",
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  0.20624902705\n",
      "Log loss on test set:  0.446713947223\n"
     ]
    }
   ],
   "source": [
    "probs_rf_train = getBestPrediction(probs_rf_train)\n",
    "probs_rf_val = getBestPrediction(probs_rf_val)\n",
    "printLoss(y_train.iloc[probs_rf_train.index.values]\n",
    "          , probs_rf_train.drop(\"device_id\",axis=1).as_matrix()\n",
    "          , y_val.iloc[probs_rf_val.index.values]\n",
    "          , probs_rf_val.drop(\"device_id\",axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RF (n_estimators=100, criterion='entropy'\n",
    "     , min_samples_split=2, min_samples_leaf=1)\n",
    "     * test score: 0.624 (0.070 train)\n",
    "* RF(... same, but criterion='gini')\n",
    "    * test score: 0.77 (0.070 train)\n",
    "* min_sample_split=100\n",
    "    * test: 1.53 (train 1.53)\n",
    "* min_sample_split=20, n_est=300\n",
    "    * test: 0.83 (train 0.76)\n",
    "* min_sample_split=4, n_est=444 (mem issues)\n",
    "    * test: 0.389 (train=0.156)\n",
    "* min_sample split=6, n=350 (prediction problem (memory), try just loading it)\n",
    "    * test: 0.442 (train 0.258)\n",
    "* min_sample 8, n_est 320\n",
    "    * test: 0.504 (train:0.353 )\n",
    "* min sample 5, n_est 270\n",
    "    * test: 0.447 (train 0.206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainedModels/rf_270_split5_entropy.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(rf, \"trainedModels/rf_350_split6_entropy.pkl\", compress=3)\n",
    "joblib.dump(rf, \"trainedModels/rf_270_split5_entropy.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rf=joblib.load(\"trainedModels/rf_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 270 out of 270 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "probs_rf_test = rf.predict_proba(test.drop(\"device_id\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function createDataSet in module __main__:\n",
      "\n",
      "createDataSet(predictions, group_encoder, device_ids)\n",
      "    Creates prediction dataset to save into csv from \n",
      "    multiclass predictions (ndarray).\n",
      "    \n",
      "    Arguments:\n",
      "    predictions   - (ndarray) predictions from the MVA.\n",
      "    group_encoder - (LabelEncoder) to transform column names.\n",
      "    device_ids    - (pd.Series, array...) respective device_ids.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(createDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_rf_test = createDataSet(probs_rf_test, enc_group, test.device_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs_rf_test.to_csv(\"finalOutputs/rf_evts_270_split5_entropy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt = GradientBoostingClassifier(loss='deviance'\n",
    "                                  ,max_features=None\n",
    "                                  , min_samples_leaf=800\n",
    "                                  , learning_rate=0.01\n",
    "                                  , n_estimators=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt = joblib.load(\"trainedModels/gbdt_evts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting done in  62.727684278041124  minutes.\n"
     ]
    }
   ],
   "source": [
    "s=time.time()/60.0\n",
    "gbdt.fit(x_train.drop(train_drop,axis=1),y_train)\n",
    "print(\"gradient boosting done in \", (time.time()/60.0)-s, \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_gbdt_test = gbdt.predict_proba(test.drop([\"device_id\"],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_gbdt_val = gbdt.predict_proba(x_val.drop(train_drop,axis=1))\n",
    "p_gbdt_train = gbdt.predict_proba(x_train.drop(train_drop,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  1.9056459881\n",
      "Log loss on test set:  1.90565042031\n"
     ]
    }
   ],
   "source": [
    "printLoss(y_val,p_gbdt_val, y_train, p_gbdt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mschlupp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "av_val = averagePredictions(p_gbdt_val, x_val.device_id.values, x_val.group.values)\n",
    "av_train = averagePredictions(p_gbdt_train, x_train.device_id.values, x_train.group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MVA predictions on test and training set:\n",
      "\n",
      "Log loss on training set:  2.29086334479\n",
      "Log loss on test set:  2.28474007692\n"
     ]
    }
   ],
   "source": [
    "printLoss(av_train.group, av_train.drop(train_drop,axis=1).as_matrix()\n",
    "          , av_val.group, av_val.drop(train_drop,axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This screams for optimisation... for now, we can go with the logreg solution."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:jupnote]",
   "language": "python",
   "name": "conda-env-jupnote-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
